{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "gkfCgw-fi2Qi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Cargar y preparar datos\n",
        "def load_and_prepare_data():\n",
        "    print(\"Cargando datos...\")\n",
        "    # Cargar datos\n",
        "    df = pd.read_csv('datos_estandarizados.csv')\n",
        "\n",
        "    # Separar features y variable objetivo\n",
        "    X = df.drop(['custcat'], axis=1)\n",
        "    y = df['custcat']\n",
        "\n",
        "    # Convertir la variable objetivo a tipo categórico\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(y)\n",
        "\n",
        "    print(\"Dimensiones de los datos:\")\n",
        "    print(f\"X shape: {X.shape}\")\n",
        "    print(f\"y shape: {y.shape}\")\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "JgRnFgJCqikO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Función para evaluar el desbalanceo de clases\n",
        "def check_class_balance(y):\n",
        "    print(\"\\nAnalizando balance de clases...\")\n",
        "    class_distribution = pd.Series(y).value_counts(normalize=True)\n",
        "    print(\"Distribución de clases:\")\n",
        "    for clase, proporcion in class_distribution.items():\n",
        "        print(f\"Clase {clase}: {proporcion:.2%}\")\n",
        "    return class_distribution\n"
      ],
      "metadata": {
        "id": "gW4y7RC1vdRg"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Pipeline principal de entrenamiento\n",
        "def train_model_pipeline(X, y):\n",
        "    print(\"\\nPreparando y entrenando modelos...\")\n",
        "    # Split de datos\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    print(\"Aplicando SMOTE para balance de clases...\")\n",
        "    # Aplicar SMOTE para balancear clases\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"Configurando modelos base...\")\n",
        "    # Crear modelos base\n",
        "    rf = RandomForestClassifier(random_state=42)\n",
        "    xgb = XGBClassifier(random_state=42)\n",
        "    svm = SVC(probability=True, random_state=42)\n",
        "\n",
        "    # Parámetros para optimización\n",
        "    rf_params = {\n",
        "        'n_estimators': [100, 200],\n",
        "        'max_depth': [10, 20],\n",
        "        'min_samples_split': [2, 5]\n",
        "    }\n",
        "\n",
        "    xgb_params = {\n",
        "        'n_estimators': [100, 200],\n",
        "        'max_depth': [3, 5],\n",
        "        'learning_rate': [0.01, 0.1]\n",
        "    }\n",
        "\n",
        "    svm_params = {\n",
        "        'C': [0.1, 1],\n",
        "        'kernel': ['rbf', 'linear']\n",
        "    }\n",
        "\n",
        "    print(\"Optimizando hiperparámetros...\")\n",
        "    # Optimizar cada modelo\n",
        "    rf_optimal = GridSearchCV(rf, rf_params, cv=5, n_jobs=-1)\n",
        "    xgb_optimal = GridSearchCV(xgb, xgb_params, cv=5, n_jobs=-1)\n",
        "    svm_optimal = GridSearchCV(svm, svm_params, cv=5, n_jobs=-1)\n",
        "\n",
        "    # Entrenar modelos optimizados\n",
        "    print(\"Entrenando Random Forest...\")\n",
        "    rf_optimal.fit(X_train_balanced, y_train_balanced)\n",
        "    print(\"Entrenando XGBoost...\")\n",
        "    xgb_optimal.fit(X_train_balanced, y_train_balanced)\n",
        "    print(\"Entrenando SVM...\")\n",
        "    svm_optimal.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "    print(\"Creando ensemble voting...\")\n",
        "    # Crear ensemble voting\n",
        "    voting_clf = VotingClassifier(\n",
        "        estimators=[\n",
        "            ('rf', rf_optimal.best_estimator_),\n",
        "            ('xgb', xgb_optimal.best_estimator_),\n",
        "            ('svm', svm_optimal.best_estimator_)\n",
        "        ],\n",
        "        voting='soft'\n",
        "    )\n",
        "\n",
        "    # Entrenar ensemble final\n",
        "    print(\"Entrenando modelo ensemble final...\")\n",
        "    voting_clf.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "    return voting_clf, X_test, y_test, rf_optimal, xgb_optimal, svm_optimal\n"
      ],
      "metadata": {
        "id": "aDp1j249vu8b"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Función para evaluar el modelo\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    print(\"\\nEvaluando modelo final...\")\n",
        "    # Predicciones\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Métricas de evaluación\n",
        "    print(\"\\nReporte de Clasificación:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Cross-validation score\n",
        "    cv_scores = cross_val_score(model, X_test, y_test, cv=5)\n",
        "    print(\"\\nCross-validation scores:\", cv_scores)\n",
        "    print(f\"Media de CV score: {cv_scores.mean():.4f}\")\n",
        "    print(f\"Desviación estándar de CV score: {cv_scores.std():.4f}\")\n",
        "\n",
        "    # Matriz de confusión\n",
        "    print(\"\\nMatriz de Confusión:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    return y_pred\n"
      ],
      "metadata": {
        "id": "f3GLfrvgvzOH"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Función principal\n",
        "def main():\n",
        "    # Cargar y preparar datos\n",
        "    X, y = load_and_prepare_data()\n",
        "\n",
        "    # Verificar balance de clases\n",
        "    class_distribution = check_class_balance(y)\n",
        "\n",
        "    # Entrenar modelo\n",
        "    voting_clf, X_test, y_test, rf_optimal, xgb_optimal, svm_optimal = train_model_pipeline(X, y)\n",
        "\n",
        "    # Evaluar modelo\n",
        "    y_pred = evaluate_model(voting_clf, X_test, y_test)\n",
        "\n",
        "    # Mostrar mejores parámetros\n",
        "    print(\"\\nMejores parámetros encontrados:\")\n",
        "    print(\"Random Forest:\", rf_optimal.best_params_)\n",
        "    print(\"XGBoost:\", xgb_optimal.best_params_)\n",
        "    print(\"SVM:\", svm_optimal.best_params_)\n",
        "\n",
        "    # Mostrar mejores scores\n",
        "    print(\"\\nMejores scores de validación:\")\n",
        "    print(f\"Random Forest: {rf_optimal.best_score_:.4f}\")\n",
        "    print(f\"XGBoost: {xgb_optimal.best_score_:.4f}\")\n",
        "    print(f\"SVM: {svm_optimal.best_score_:.4f}\")\n",
        "\n",
        "    return voting_clf\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEcS90nDv1gE",
        "outputId": "f19e2c4f-171b-45ad-d3cd-befa6d7cf85a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando datos...\n",
            "Dimensiones de los datos:\n",
            "X shape: (1000, 11)\n",
            "y shape: (1000,)\n",
            "\n",
            "Analizando balance de clases...\n",
            "Distribución de clases:\n",
            "Clase 2: 28.10%\n",
            "Clase 0: 26.60%\n",
            "Clase 3: 23.60%\n",
            "Clase 1: 21.70%\n",
            "\n",
            "Preparando y entrenando modelos...\n",
            "Aplicando SMOTE para balance de clases...\n",
            "Configurando modelos base...\n",
            "Optimizando hiperparámetros...\n",
            "Entrenando Random Forest...\n",
            "Entrenando XGBoost...\n",
            "Entrenando SVM...\n",
            "Creando ensemble voting...\n",
            "Entrenando modelo ensemble final...\n",
            "\n",
            "Evaluando modelo final...\n",
            "\n",
            "Reporte de Clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.40      0.41        60\n",
            "           1       0.29      0.31      0.30        39\n",
            "           2       0.45      0.47      0.46        55\n",
            "           3       0.28      0.26      0.27        46\n",
            "\n",
            "    accuracy                           0.37       200\n",
            "   macro avg       0.36      0.36      0.36       200\n",
            "weighted avg       0.37      0.37      0.37       200\n",
            "\n",
            "\n",
            "Cross-validation scores: [0.325 0.35  0.3   0.275 0.325]\n",
            "Media de CV score: 0.3150\n",
            "Desviación estándar de CV score: 0.0255\n",
            "\n",
            "Matriz de Confusión:\n",
            "[[24 13 13 10]\n",
            " [ 4 12 11 12]\n",
            " [15  5 26  9]\n",
            " [15 11  8 12]]\n",
            "\n",
            "Mejores parámetros encontrados:\n",
            "Random Forest: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 100}\n",
            "XGBoost: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
            "SVM: {'C': 1, 'kernel': 'rbf'}\n",
            "\n",
            "Mejores scores de validación:\n",
            "Random Forest: 0.4737\n",
            "XGBoost: 0.4382\n",
            "SVM: 0.4226\n"
          ]
        }
      ]
    }
  ]
}